---
title: 'Assignment: Classification of Weight Lifiting Exercise Feedbacks'
author: "Rajesh Rajendran"
date: '2022-05-31'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r library_calls, message=FALSE, warning=FALSE, results='hide'}
library(caret)
library(rpart)
library(randomForest)
library(gbm)
set.seed(12345)
```

## Introduction
In this assignment we analyse the data from a Weight Lifting Exercise activity. Create a machine learning model to predict the manner in which they did the exercise. Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). The data for this analysis come from source <http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har>. 

The dataset used in this project can be found [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv), and the experiment details are described in the original [paper](http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf).

## Data Cleaning
Download the data for training & testing set
```{r download_data, cache=TRUE}
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
```

```{r dim, echo=TRUE}
dim(training)
dim(testing)
```
Train set has 19622 observations of 160 variables. Test set has 20 observations of 160 variables. It can be seen that lot of columns in train and test set are missing. In train set the missing values are also in form of empty strings. First convert empty string to NA's.
```{r str2NA, echo=TRUE}
training[training==""]<-NA
```

**Check for missing values:**
```{r nas, echo=TRUE}
col_sums_na <- colSums(is.na(training))
col_sums_na[col_sums_na>0]
```
Several columns have a more than 95% of values missing. It's not possible to interpolate fill the missing values. All columns has same number of missing values. so let's omit the columns with the missing values.
``` {r missing, echo=TRUE}
cols_na <- names(col_sums_na[col_sums_na>0])
training <- subset(training,select = !(names(training)%in%cols_na))
testing <- subset(testing,select = !(names(testing)%in%cols_na))
dim(training)
dim(testing)
```
Let's look at the classe variable
```{r tclasse, echo=TRUE}
str(training$classe)
table(training$classe)
```

Convert calsse into factor variable, & remove variable's related to timestamp & index from the predictors
```{r tofactor, echo=TRUE}
training$classe <- as.factor(training$classe)

training<- subset(training,select=-c(X,new_window,num_window,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp))
testing<- subset(testing,select=-c(X,new_window,num_window,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp))
#training$user_name <- as.factor(training$user_name)
#testing$user_name <- as.factor(testing$user_name)
```

Split data into training and validation set
```{r splitdata}
inTrain <- createDataPartition(y=training$classe,p=0.75,list=FALSE)
validation <- training[-inTrain,]
training <- training[inTrain,]
```

## Model Building:
Build 3 different models

* rpart model
* randorm forest model
* Bagging based gbm model

Choose the model that produce more accurate result. Here, we apply cross validation 
on each model. As we have ample amount of data for training, let's choose 
smaller number of folds for cross validation (k=3). The resulting models will be
more biased towards training data and has less variance.

```{r model_training, cache=TRUE}
cv3 <- trainControl(method='cv',number=3,allowParallel = TRUE)
modRpart <- train(classe~., data=training,method='rpart',trControl=cv3)
modRf <- train(classe~., data=training,method='rf',trControl=cv3)
modGbm <- train(classe~., data=training,method='gbm',trControl=cv3)
```
Calculate the Out of sample accuracy with Validation data. And choose the 
model with highest accuracy

```{r accuracy, echo=TRUE}
# Accuracy of Regression Trees model
sum(predict(modRpart,validation)==validation$classe)/dim(validation)[1]
# Accuracy of Random Forest model
sum(predict(modRf,validation)==validation$classe)/dim(validation)[1]
# Accuracy of GBM
sum(predict(modGbm,validation)==validation$classe)/dim(validation)[1]
```

The Random Forest model's accuracy is bigger than rpart and gbm model. Choose 
random forest model as final selected model.

Now predict the testing data with final model
```{r ans, echo=TRUE}
predict(modRf,testing)
```